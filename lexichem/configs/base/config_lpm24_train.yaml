method: 'base'
seeds: 
  - 1480
  - 1000
  - 256
  - 2943
  - 199
t5:
  pretrained_model_name_or_path: 'QizhiPei/biot5-plus-base'
  dropout: 0.1
lr:
  backbone: 3e-5
trainer:
  max_steps: 100000
  val_check_interval: 2000
  batch_size: 8
  grad_accum: 1
  num_workers: 4
  cuda: true
  strategy: 'ddp'
  num_devices: 4
  warmup_ratio: 0.1
  precision: '32'
  dataset_name: 'lpm-24'
  output_folder: 'weights/'
  do_enumeration: true
optuna:
  use_optuna: false
  n_trials: 10
project:
  name: 'LexiChem-Base-LPM24'